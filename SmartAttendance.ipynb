{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1487bec8-7076-4931-8ef3-e2335a4f5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 2: Model Training and Validation\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebbebc7-2b2e-437a-ac08-93d1dcb5dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the dataset directories\n",
    "train_dir = os.path.join('student_images', 'train')\n",
    "val_dir = os.path.join('student_images', 'validation')\n",
    "test_dir = os.path.join('student_images', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c113aaeb-4879-481e-8ee7-6a00576ca87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a72a1b-ec1f-4bba-821c-37e937e0f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images and labels from a directory\n",
    "def load_images(data_dir, image_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, label)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.resize(image, image_size)\n",
    "                images.append(image)\n",
    "                labels.append(int(label))\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aebe3b9-517e-4566-ad3e-f117741dbcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "X_train, y_train = load_images(train_dir)\n",
    "X_val, y_val = load_images(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80397845-5d2d-4cb4-bc33-bbda8bbd23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce image size\n",
    "resize_shape = (112, 112)  # Adjust as needed\n",
    "\n",
    "X_train_resized = np.array([cv2.resize(img, resize_shape) for img in X_train])\n",
    "X_val_resized = np.array([cv2.resize(img, resize_shape) for img in X_val])\n",
    "\n",
    "# Normalize images\n",
    "X_train_resized = X_train_resized / 255.0\n",
    "X_val_resized = X_val_resized / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8853d288-ed73-4098-b6ca-f5c1ac58dfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Clear cache and force garbage collection\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1cc4f2c-dd7a-411a-bac6-4294d0ce08cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10512 images belonging to 18 classes.\n",
      "Found 4303 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the ImageDataGenerator for training with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Define the ImageDataGenerator for validation without augmentation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define directories (adjust paths as needed)\n",
    "current_dir = os.getcwd()\n",
    "train_dir = os.path.join(current_dir, 'student_images', 'train')\n",
    "val_dir = os.path.join(current_dir, 'student_images', 'validation')\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081052b9-646e-41e0-8c63-ccd4ea6ae294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(18, activation='softmax'),\n",
    "    Dense(18, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cedf09f2-4ffb-48dd-a371-2def8fcb586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ce0e8-e116-4550-8613-d74d7aa273e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94239b4a-c432-4f27-9c0a-0f29751cd66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 2s/step - accuracy: 0.2262 - loss: 2.6805 - val_accuracy: 0.2750 - val_loss: 2.4490\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/328\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:24\u001b[0m 2s/step - accuracy: 0.3438 - loss: 2.4763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993us/step - accuracy: 0.3438 - loss: 1.2419 - val_accuracy: 0.2667 - val_loss: 1.2330\n",
      "Epoch 3/10\n",
      "\u001b[1m 76/328\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:03\u001b[0m 2s/step - accuracy: 0.2614 - loss: 2.5078"
     ]
    }
   ],
   "source": [
    "# Model training with the data generators\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,  # Adjust number of epochs as needed\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4dba2-f656-4a10-8c3d-a685dc736263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_dir = 'models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_dir, 'facial_recognition_model.keras')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de3196-7379-473d-af7d-98c81bd902e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3: Real-time Recognition and Attendance Marking\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a90e90-1c7e-4051-96b6-8552e605c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load student records from SQLite database\n",
    "def load_student_records(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    students_db = pd.read_sql_query('SELECT * FROM students', conn)\n",
    "    conn.close()\n",
    "    return students_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783205df-ce70-41d9-9efa-34c3316f5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the student records\n",
    "students_db = load_student_records('student_attendance.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8546d4-22c4-4d75-b446-d00fbfb99fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print student records to verify\n",
    "print(students_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11a6f9-792b-40e3-acc9-a517696ac37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time recognition function\n",
    "def recognize_and_display():\n",
    "    for img_name in os.listdir(test_dir):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        \n",
    "        # Check if the image path exists\n",
    "        if not os.path.isfile(img_path):\n",
    "            print(f\"Image file '{img_path}' does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Check if the image was successfully read\n",
    "        if img is None:\n",
    "            print(f\"Failed to read image '{img_path}'.\")\n",
    "            continue\n",
    "        \n",
    "        faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            face = img[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "            face = face / 255.0\n",
    "            face = np.expand_dims(face, axis=0)\n",
    "            \n",
    "            predictions = model.predict(face)\n",
    "            predicted_label = np.argmax(predictions[0])\n",
    "            \n",
    "            student_name = students_db.loc[students_db['student_id'] == predicted_label, 'student_name'].values[0]\n",
    "            \n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(img, student_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "        \n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Image: {img_name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Call the function\n",
    "recognize_and_display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
